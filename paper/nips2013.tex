\documentclass{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{amssymb}
\usepackage{graphicx}
%\documentstyle[nips13submit_09,times,art10]{article} % For LaTeX 2.09

% sample NIPS papers -  http://papers.nips.cc/

\title{Path and Relationship Discovery Using Sparse Recovery and Compressive Sensing}

\author{
Harshal Chaudhari\\
Boston University \\
\texttt{harshal@bu.edu} \\
\And
Yu (Albert) Chen\\
Boston University \\
\texttt{chenyua@bu.edu} \\
\And
Shan Sikdar\\
Boston University  \\
\texttt{ssikdar1@bu.edu} \\
\And
Jacqueline You\\
Boston University \\
\texttt{jgyou@bu.edu} \\
}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.


\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}


\nipsfinalcopy % Uncomment for camera-ready version



\begin{document}


\maketitle

\begin{abstract}
Frequently real world problems involve datasets with a large number of instances and a small amount of partial information about the relationship between individual instances. Often, it is important to infer the structure of the data so that given a data point one can discover its relationship to other nodes and gather important information. In this paper, we have attempted to solve this problem by reducing the problem to path discovery.  Our dataset was obtained from the “Identity Discovery Challenge”. Given a partial New York City phone number and an address in Maryland, we were tasked with finding the relationship between the two pieces of information in order to identify a male who could potentially be carrying a contagious disease.  A variety of compressive sensing and sparse methods were utilized in order to solve the challenge including sparse graph recovery, shortest path algorithms, page rank, and compressive sensing techniques such as $\ell_1$-minimization. Our experiments suggest that relationships and paths can be inferred and used in real life applications for identity discovery.
\end{abstract}


\section{Introduction}
%talk about compressive sensing + graphs/clique detection/other relevant matters


Compressive sensing has emerged within the past decade as a new method of signal/image sampling that challenges traditional methods that rely on high sampling rates. This technique was first described in works [Candes' 2 original papers] [Donoho's original paper] and centers on two concepts - sparsity and incoherence. Sparsity measures how concisely a signal can be represented as, while incoherence is a measure of the lack of correlation between the sensing basis $\phi$ and the representation basis $\psi$ . Generally, compressive sensing problems are framed as the recovery of $x$, a discrete signal, from $y$, the sampled/sensed data. $x \in  \mathbb{R}^n$ is recovered from $y=Ax \in  \mathbb{R}^m $, where $m$ is the number of available measurements, $n$ is the dimension of the signal $y$, $A$ is the $m \times n$ sensing matrix, and $m << n$  in undersampled situations [Candes intro article].


Compressive sensing's applications extend beyond digital images and digital signals. Compressive sensing can also be utilized to examine cliques, groups, and networks. [Shi,Tang,Xu, Moscibroda] [Siyari] [Haupt] Compressive sensing has also been applied in a variety of ways in medicine, including increasing the efficiency of magnetic resonance imaging (MRI) through compressive sensing reconstruction [Lutsig et al]; using compressive sensing approaches (Gradient Projection for Sparse Reconstruction and Belief Propogation) for screening of rare genetic diseases [Erlich etal]; and by using probabilistic tests and compressive sensing to identify a group of infected individuals [Cheraghchi et al]. 

In our work, we attempted to use compressive sensing to tackle a hypothetical epidemiological scenario. We used compressive sensing to aid us in path discovery in a graph. We experimented and attempted many methods including sparse graph recovery, $\ell_1$- minimization, page rank and shortest path algorithms.


\section{Problem Premise}




We were tasked with determining the identity of an unknown male individual given a fictitious set of records. In this hypothetical scenario, the unidentified man had visited a Maryland hospital and had potentially infected another patient with a deadly disease. Authorities trying to locate this man only had an incomplete version of his phone number (with a New York City area code). The challenge was to identify the individual using these facts and a data set of records. 




The data set consisted of a list of approximately 350,000 nodes and another list of approximately 68,000 edges corresponding to these nodes. Each node consisted of the following attributes: first name, last name, middle name, street, city, state, zip, phone number, and ID-DOC. The man's incomplete phone number \texttt{21299875XX} was designated as "Seed 1" while the hospital's address, \texttt{4408 East Madison Ave., Bethesda, MD 20014}, was designated as "Seed 2."




The edges were produced through an entity resolution and fuzzy matching process, and for each pair of edges, there was a set of attribute pair scores (APS) which were then combined to yield a total composite score (TCS). When represented as an adjacency matrix, this data set was sparse due to the relatively low number of edges.


%http://www.tablesgenerator.com/latex_tables


Sample Node


\begin{table}[h]
\centering
\tiny
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
\textbf{Source} & \textbf{GUID} & \textbf{LastName} & \textbf{MiddleName} & \textbf{FirstName} & \textbf{Street} & \textbf{City} & \textbf{State} & \textbf{Zip} & \textbf{Phone} & \textbf{ID-DOC} \\ \hline
CCCR & CCCR-a57685ee-ba9f... & Brandybuck & Donnamira & Gloriana & 2719 Pin Oak Drive & Manhattan & NY & 10018 &  & 5334856597493120 \\ \hline
\end{tabular}
\end{table}


Sample Edge

\begin{table}[h]
\tiny
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|l|}
\hline
\textbf{EDGE\_ID} & \textbf{GUID\_1} & \textbf{GUID\_2} & \textbf{Last\_APS} & \textbf{Mid\_APS} & \textbf{First\_APS} & \textbf{Street\_APS} & \textbf{City\_APS} & \textbf{State\_APS} & \textbf{Zip\_APS} & \textbf{Phone\_APS} & \textbf{ID-DOC\_APS} & \textbf{TCS} \\ \hline
Edge\_2421 & SRLU-2a... & CCCR-a... & 1 & 0.7777778 & 1 & 0.05263 & 0 & 1 & 0 & 0 & 0 & 0.4788 \\ \hline
\end{tabular}
\end{table}

We decided that this problem eventually boiled down to path discovery between the two SEED nodes. We then began exploring and experimenting with ways to most efficiently determine this path.

\section{Linear Regression}

We first attempted to recover more edge information of the graph by using linear regression to produce an equation that could help derive us more edges between the nodes of the graph. Since the edge contained both an ''Attribute Pair Score'' (APS) for each variable and a ''Total Composite Score''(TCS) for each $i$, we believed that the total composite score (TCS) for each $i$th pair of nodes could be expressed as follows:
\[
TCS = b_0x_0 + b_1x_1 + b_2x_2 + ... + b_nx_n
\]

where $x_k$ is an APS attribute score for a particular variable. Using linear regression, we intended to determine the formula's constants used to calculate the TCS score. For any two nodes, this would then allow us to utilize fuzzy matching to create APS scores and use the equation to calculate a TCS as the edge weight.

However, we discovered that the runtime for reconstructing the graph would be $O(n^2)$; thus this approach was not suitable for our data.


\section{Page Rank Algorithm}

PageRank is an algorithm developed by Larry Page from Google used to rank websites in their search engine results. It is a link analysis algorithm that tries to weigh each element in order to measure its relative importance to the entire collection. The algorithm outputs a probability distribution used to represent the likelihood that a person randomly clicking on a link will arrive at any particular page. We attempted to use PageRank to solve this challenge by using the information stored in the nodes as opposed to web content.



\section{Finding Shortest Path}
We proceeded to treat the data set as a graph $G = (V,E)$, where $V$ corresponds to the individual records/nodes and $E$ corresponds to the linkages between records with an edge weight of $(1-TCS)$. We sought paths between Seed 1 and Seed 2 with total edge weights below a designated threshold so that we could identify a number of potential disease carriers along with related individuals (family, friends, et cetera). We then used the provided information and the data set to determine which individuals were most likely to be our person of interest. As detailed in our results, this method worked successfully; however, it suffered from a lack of generalizability to other problems. 

%[or add some other explanation]



\section{Compressive Sensing Techniques}


\subsection{Radon Basis Pursuit}
[Jiang et al] introduced a network data representation framework that allowed for the use of compressive sensing to study the network clique detection problem. They demonstrated that higher-level cliques could be extracted from analysis of a group of people by using radon basis pursuit. Through this approach, the clique detection problem is formulated into a compressive sensing problem.

A network is modeled as a graph $G = (V, E)$, where $V= \{ 1, ..., n \}$ is a set of nodes and $E \subset V \times V$ is the set of edges. A number of important measures are defined as follows: $b$ is a vector of the upper-triangle elements in $B \in  \mathbb{R}^{n \times n}$, the adjacency matrix of a network whose elements indicate the observed frequencies of lower-order subsets; $A$ is an $m \times n$ basis dictionary, with each basis representing a clique; and $x$ is a vector containing the unknown frequencies of higher-order subsets. The reconstruction program used accounted for noise:
\[
(\wp_{1,\delta}) 	min ||x||_1 s.t. ||Ax-b||_{\infty} \leq \delta
\]

However, a number of limitations to this approach include the combinatorial increase in basis size, and the need for a binary weight of edges (i.e. edges are weighed either 0 or 1); thus this approach ultimately was not suitable for our problem. 

%#####

\subsection{Sparse Recovery with Graphs}
Previous work in sparse recovery of graphs has been done in situations in which a weight is associated with each vertex [Wang,Xu, Mallada, Tang]. Using this approach we hoped to obtain communities of nodes similar to the original SEED node. 

Consider the graph $G = (V,E)$, where $V$ is the set of all vertices $x_1 , x_2 , .... , x_n$  and $E$ is the set of edges between any two vertices. Consider only the connected components of $G$. Let $x = \{x_1, x_2, x_3, ... , x_n\}$. Note that $x$ should be sparse since we assume very few nodes are similar to the SEED-1 node. 
Let the support of the vector $x$ be defined to be a vector with its entries being the non-zero indices of $x$, in other words: $\textrm{supp}_x :=\{x_i | x_i \neq  0\}$. Then, $||x||_0 = |\textrm{supp}_x|$. $x$ is defined to be $k$-sparse if $ |\textrm{supp}_x| = k$.

Looking at a subset of nodes  $S \subseteq G$, define $E_S$ as the subset of edges with its vertices in S. Then $G_S = (S,E_S)$ is a induced subgraph of $G$. From here, two assumptions must be made about the measurements of $S$. First, a set of nodes $S$ can be measured iff $G_S$ is a connected subgraph. Secondly, the measurements of $S$ must be additive sums of values at the corresponding nodes. A single specific measurement is obtained by randomly selecting a node in the connected component and performing an additive sum of the tree with depth $h$ from the given node. In relation to the identity challenge, this measurement would represent how similar a particular induced subgraph of $G$ is similar to the SEED node.

Let $y = \{ y_1, y_2, y_3 ... y_m \}$ denote randomly chosen measurements such that $m << n$.  Let $A$ be an $m x n$ measurement matrix such that its $i$th row corresponds to the $i$th measurement.  For a particular entry $A_{ij}$, $A_{ij} = 1$ if  node $j$ is included in the $i$th measurement and $A_{ij} = 0$ otherwise.
Note that we can write the above situation much more compactly as $y = Ax$. This equation is now in the same form used in compressive sensing and sparse recovery.  Compressive sensing theory suggests that the $n$-dimensional vectors can be found from $m$ measurements if the vectors are sparse enough. Therefore $\ell_1$- minimization can be used to recover the sparse vectors using $m$ random measurements.  After the vectors are recovered, the maximal entries in $x$  will denote the nodes most similar to the SEED node. Thus this can be seen as the set of potential disease carriers and a shortest path approach should be able to identify the person.
\subsection{$\ell_1$--minimization}
should this be here? or should a discussion about which $\ell_1$ minimization technique used from L1 magic in the section above and/or results



\section{Results}

\subsection{Linear Regression}
Using the linear regression method described above, we successfully found the relevant weights. The results ended up being very interesting, with the APS of ID-DOC having the largest weight. Upon browsing through the dataset it was shown the the ID-DOC did not appear often compared to other variables. A high weight would possibly indicate that when two nodes have a close matching ID-DOC score, the nodes' relationship is very important. 
\begin{table}[h]
\centering
\tiny
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline

 $\textbf{APS}_{\textbf{LastName}}$ & $\textbf{APS}_{\textbf{FirstName}}$ &  $\textbf{APS}_{\textbf{Middle}}$ &$\textbf{APS}_{\textbf{phone}}$ & $\textbf{APS}_{\textbf{state}}$ & $\textbf{APS}_{\textbf{City}}$ & $\textbf{APS}_{\textbf{Street}}$ & $\textbf{APS}_{\textbf{Zip}}$ & $\textbf{APS}_{\textbf{ID-DOC}}$   \\ \hline

-0.1293 & -0.1708 &  -0.3292 &0.1341 & -0.5251 & 0.1580 &  0.2225 & -0.1707 & 1.0561  \\ \hline
\end{tabular}
\end{table}

\subsection{Page Rank}

\subsection{Shortest Path}
The initial shortest path returned a series of nodes that primarily included information about a woman. Since the information provided indicated the person of interest was male, the last edge between the final pair of nodes on the shortest path was removed and the shortest path algorithm was run again. This time the shortest path eventually led us to nodes containing information about a male. Upon investigating the intersection sets of the paths, information was found possibly sugessting that the woman in the first path was in fact married to the man identified in the second path. After obtaining the second shortest path, we again removed the last edge in the path and ran the shortest path algorithm on the remaining graph.The algorithm yieled no shortest path between the two nodes. 

First Shortest Path:

\begin{table}[h]
\centering
\tiny
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
\textbf{Source}  & \textbf{LastName} & \textbf{MiddleName} & \textbf{FirstName} & \textbf{Street} & \textbf{City} & \textbf{State} & \textbf{Zip} & \textbf{Phone} & \textbf{ID-DOC} \\ \hline

%SEED &   NaN & NaN  & NaN & NaN & NaN & NaN & 2129887XX  &  NaN \\ \hline
%SLRU &  NaN & Brandybuck  & D & Gloriana & 3306 Rosewood Lane & New York& NY &10003    & 2129987506       &  NaN \\ \hline
Source &LastName &MiddleName &FirstName &Street &City &State & Zip & Phone & ID-DOC \\ \hline
  SEED  &     NaN &       NaN &      NaN &   NaN & NaN &  NaN & NaN &   21299875XX &    NaN \\ \hline
  SRLU  & Brandybuck &  D & Gloriana & 3306 Rosewood Lane & New York &   NY &10003&2129987506&    NaN \\ \hline
  CCCR  & Brandybuck & Donnamira &  Gloriana & 2719 Pin Oak Drive & Manhattan &   NY &10018&  NaN &5.33E+15\\ \hline
  CCTR  &     NaN &       NaN &  NaN &  18 Wayback Road & Bethesda &   MD &20014&  NaN &5.33E+15\\ \hline
  CCTR  &     NaN &       NaN &   NaN & 1323 Frosty Lane &     Lodi &   NY &14860&  NaN &4.49E+15\\ \hline
  SEED  &     NaN &       NaN &      NaN & 4408 East Madison Ave.  &Bethesda&   MD &20014&  NaN &    NaN \\ \hline
\end{tabular}
\end{table}

Second Shortest Path:
\begin{table}[h]
\centering
\tiny
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
\textbf{Source}  & \textbf{LastName} & \textbf{MiddleName} & \textbf{FirstName} & \textbf{Street} & \textbf{City} & \textbf{State} & \textbf{Zip} & \textbf{Phone} & \textbf{ID-DOC} \\ \hline

%SEED &   NaN & NaN  & NaN & NaN & NaN & NaN & 2129887XX  &  NaN \\ \hline
%SLRU &  NaN & Brandybuck  & D & Gloriana & 3306 Rosewood Lane & New York& NY &10003    & 2129987506       &  NaN \\ \hline
Source & LastName& MiddleName& FirstName& Street& City& State&  Zip&   Phone&  ID-DOC  \\ \hline
SEED&        NaN&        NaN&    NaN&   NaN&  NaN&   NaN&  NaN&   21299875XX&     NaN \\ \hline
   SRLU&  Brandybuck&   D&  Gloriana&  3306 Rosewood Lane&  New York&  NY&  10003&   2129987506&     NaN  \\ \hline
   CCCR&   Brandybuck&  Donnamira&   Gloriana&  2719 Pin Oak Drive&  Manhattan&    NY&  10018&   NaN&  5.334857e+15      \\ \hline
  HPA&    Took&        NaN&   Tollman&  Pin Oak Dr& Manhattan&    NY&  10018&   NaN&     NaN     \\ \hline
    ID&    Took&   Fredegar&   Tolman&  234 Trails End Rd.&  Staten Island&    NY&  10301&   NaN&   298808448 \\ \hline
   TR&       Tuk&          F&     Tom&    NaN&  NaN&   NaN&  NaN&  6318085343&  298808448  \\ \hline
   HR&        NaN&        NaN&    NaN&  322 Meadow Dr.&  Bethesda&    MD&  20014&  6318085343&     NaN  \\ \hline
   WP&  Hornblower&        NaN&    Melilot&  322 Doe Meadow Drive&  Bethesda&    MD&  20014&  3018035414&    NaN  \\ \hline
   SEED&     NaN&        NaN&       NaN&  4408 East Madison Ave.&    Bethesda&    MD&  20014&   NaN&     NaN  \\ \hline
\end{tabular}
\end{table}

\subsection{Sparse Recovery of Graph}




\section{Conclusion}
In conclusion 







\subsubsection*{References}
\small{
%% the NIPS site states that any citation style is fine, as long as you number the references - I used IEEE format but this can be changed if needed (JY)
%% http://dal.ca.libguides.com/content.php?pid=860&sid=11818#ieexapa

%%% PLEASE NUMBER THESE

% Candes/Romberg/Tao's original paper
% http://statweb.stanford.edu/~candes/papers/ExactRecovery.pdf
% http://statweb.stanford.edu/~candes/papers/OptimalRecovery.pdf

[A0] E. Cand\'{e}s, J. Romberg, and T. Tao, "Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information," {\it IEE Trans. Inform. Theory}, vol. 52, no.2, pp.489-509, Feb. 2006.

[A1] E. Cand\'{e}s and T. Tao, "Near optimal signal recovery from random projections: Universal encoding strategies?" {\it IEEE Trans. Inform. Theory}, vol. 52, no. 12, pp. 5406-5425, Dec. 2006.

[A2] D. L. Donoho, "Compressed sensing," {\it IEEE Trans. Inform. Theory}, vol. 52, no. 4, pp. 1289-1306, Apr. 2006.

% http://dsp.rice.edu/sites/dsp.rice.edu/files/cs/CSintro.pdf
[A3] E. Cand\'{e}s and M. B. Wakin, "An introduction to compressive sampling," {\it IEEE Signal Process. Mag.}, vol. 25, no. 2, pp. 21-30, Mar. 2008.


% 3 papers on compressive sensing for networked data
% microsoft paper
% correlated compressive sensing for networked data
% http://research.microsoft.com/en-us/um/people/moscitho/Publications/UAI_2014.pdf

[B] T. Shi, D. Tang, L. Xu, and T. Moscibroda, "Correlated compressive sensing for networked data," in {\it The 30th Conference on Uncertainty in Artificial Intelligence (UAI)}, 2014, pp. 722-731.

%http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&arnumber=6542417
%http://web.engr.illinois.edu/~eslamim2/publications/Siyari-SocialInf12.pdf
[C] P. Siyari, H.R. Rabiee, M. Salehi, and M. Mehdiabadi, "Network reconstruction under compressive sensing," in {\it 2012 International Conference on Social Informatics}, 2012, pp. 19-25.

% http://www.ece.umn.edu/~luo../jdhaupt/publications/spmag07_cs_networked_data.pdf
[D] J. Haupt, W. U. Bajwa, M. Rabbat, and R. Nowak, "Compressed sensing for networked data," {\it IEEE Signal Process. Mag.}, vol. 25, no. 2, pp. 92-101, Mar. 2008.

% MRI http://www.ncbi.nlm.nih.gov/pubmed/17969013
[E] M. Lustig, D. Donoho, and J. M. Pauly, "Sparse MRI: The application of compressed sensing for rapid MR imaging," {\it Magn. Reson. Med.}, vol. 58, no. 6, 1182-1195, Oct. 2007.

%  Genetic screening http://pluto.huji.ac.il/~orzu/publications/Erlich_et_al_allerton_2009.pdf
[F] Y. Erlich, N. Shental, A. Amir, and O. Zuk, "Compressed sensing approach for high throughput carrier screen," in {\it 47th Annual Allerton Conference on Communication, Control}, 2009, pp. 539-544.

% Grouping epidemiology, http://arxiv.org/pdf/1009.3186.pdf
[G] M. Cheraghchi, A. Hormati, A. Karbasi, and M. Vetterli, "Group testing with probabilistic tests: Theory, design and application," {\it IEEE Trans. Inform. Theory,} vol. 57,  no. 10, pp. 7057-7067, Jul. 2011.

%%%% Compressive sensing algorithms

%http://jmlr.org/proceedings/papers/v22/jiang12/jiang12.pdf
[X] X. Y. Jiang, Y. Yao, H. Liu, and L. Guibas, "Detecting network cliques with radon basis pursuit," in {\it Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS)}, 2012, pp. 565-573.

%http://people.ece.cornell.edu/atang/pub/12/Infocom12.pdf
[?] M. Wang, W. Xu, E. Mallada, and A. Tang, "Sparse recovery with graph constraints: Fundamental limits and measurement construction," in {\it 2012 Proceedings IEEE INFOCOM}, 2012, pp. 1871-1879.



\end{document}